#!/usr/bin/env bash
################################################################################
# ðŸ”¬ ULTIMATE E2E DOCKER IMAGE â†’ PRE-COMPILE RECOVERY FRAMEWORK
# Version: 2026.2 â€” Military-Grade Research-Validated Pipeline
#
# Mission: Complete reconstruction of Docker images to original pre-compilation state
#          including Dockerfile, docker-compose, source code, configs, secrets, 
#          runtime state, SBOM, vulnerabilities, and forensic artifacts.
#
# Enhanced Features:
# â€¢ Military-grade error handling with detailed logging
# â€¢ Parallel processing for performance optimization
# â€¢ Comprehensive tool integration (Syft, Grype, Whaler, Dive, Skopeo, Crane, 
#   Tetragon, Falco, Docker Forensics Toolkit, eBPF tools)
# â€¢ Advanced secret detection with pattern matching
# â€¢ Multi-language source code recovery with decompilation
# â€¢ Real-time progress monitoring and reporting
# â€¢ Intelligent fallback mechanisms
# â€¢ Resource management and system health monitoring
# â€¢ Comprehensive artifact verification
# â€¢ Security-focused analysis with offensive capabilities
#
# Usage: ./docker-decompose-enhanced.sh <IMAGE:TAG> [OUTPUT_DIR] [CONTAINER_ID]
# Example: ./docker-decompose-enhanced.sh nginx:latest ./extracted abcdef123456
#
# Research Basis: 2025-2026 industry research, CNCF projects, academic papers
################################################################################

set -euo pipefail

# =============================================================================
# GLOBAL CONFIGURATION
# =============================================================================

# Script metadata
readonly SCRIPT_VERSION="2026.2"
readonly SCRIPT_NAME="Ultimate Docker Decomposition Framework"
readonly RESEARCH_DATE="January 2026"

# Colors for output
readonly RED='\033[0;31m'
readonly GREEN='\033[0;32m'
readonly YELLOW='\033[1;33m'
readonly BLUE='\033[0;34m'
readonly MAGENTA='\033[0;35m'
readonly CYAN='\033[0;36m'
readonly NC='\033[0m' # No Color
readonly BOLD='\033[1m'
readonly DIM='\033[2m'

# Configuration with environment variable support
readonly IMAGE="${1:-}"
readonly OUTPUT_DIR="${2:-./extracted}"
readonly CONTAINER_ID="${3:-}"
readonly FORCE_OVERWRITE="${FORCE_OVERWRITE:-false}"
readonly PARALLEL_JOBS="${PARALLEL_JOBS:-4}"
readonly SKIP_RUNTIME="${SKIP_RUNTIME:-false}"
readonly SKIP_OFFENSIVE="${SKIP_OFFENSIVE:-true}"
readonly DEEP_SCAN="${DEEP_SCAN:-false}"
readonly ENABLE_FORENSICS="${ENABLE_FORENSICS:-true}"
readonly LOG_LEVEL="${LOG_LEVEL:-INFO}"
readonly MAX_RETRIES="${MAX_RETRIES:-3}"
readonly TIMEOUT="${TIMEOUT:-300}"

# Tool versions (minimum required)
readonly MIN_SYFT_VERSION="0.60.0"
readonly MIN_GRYPE_VERSION="0.51.0"
readonly MIN_WHALER_VERSION="1.5.0"
readonly MIN_DIVE_VERSION="0.10.0"

# Resource limits
readonly MAX_MEMORY_GB="${MAX_MEMORY_GB:-8}"
readonly MAX_DISK_SPACE_GB="${MAX_DISK_SPACE_GB:-50}"

# =============================================================================
# GLOBAL VARIABLES
# =============================================================================

# Script state
declare -g SCRIPT_START_TIME
declare -g CURRENT_PHASE=""
declare -g PHASE_START_TIME
declare -g TOTAL_PHASES=12
declare -g COMPLETED_PHASES=0
declare -g ERROR_COUNT=0
declare -g WARNING_COUNT=0

# Tool availability flags
declare -g HAS_SYFT=false
declare -g HAS_GRYPE=false
declare -g HAS_WHALER=false
declare -g HAS_DIVE=false
declare -g HAS_SKOPEO=false
declare -g HAS_CRANE=false
declare -g HAS_KOMPOSE=false
declare -g HAS_HELM=false
declare -g HAS_PYTHON3=false
declare -g HAS_UNCOMPILE6=false
declare -g HAS_VOLATILITY=false

# Output directories
declare -g OUTPUT_ROOT
declare -g LOG_FILE
declare -g REPORT_FILE
declare -g METRICS_FILE

# Process tracking
declare -g -a BACKGROUND_PROCESSES=()

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

# Enhanced logging system
log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    local color=""
    
    case "$level" in
        "DEBUG") color="$DIM" ;;
        "INFO") color="$BLUE" ;;
        "WARN") color="$YELLOW" ;;
        "ERROR") color="$RED" ;;
        "SUCCESS") color="$GREEN" ;;
        "PHASE") color="$MAGENTA" ;;
        *) color="$NC" ;;
    esac
    
    # Only log if level matches or exceeds configured level
    if [[ "$level" == "ERROR" ]] || \
       [[ "$level" == "WARN" && "$LOG_LEVEL" != "ERROR" ]] || \
       [[ "$level" == "INFO" && "$LOG_LEVEL" != "ERROR" && "$LOG_LEVEL" != "WARN" ]] || \
       [[ "$level" == "DEBUG" && "$LOG_LEVEL" == "DEBUG" ]] || \
       [[ "$level" == "PHASE" ]] || \
       [[ "$level" == "SUCCESS" ]]; then
        
        echo -e "${color}[$timestamp] [$level]${NC} $message" | tee -a "$LOG_FILE"
    fi
}

# Progress tracking
show_progress() {
    local current="$1"
    local total="$2"
    local phase_name="$3"
    local width=50
    local percentage=$((current * 100 / total))
    local completed=$((percentage * width / 100))
    local remaining=$((width - completed))
    
    printf "\r${CYAN}[PHASE %d/%d]${NC} %s " "$current" "$total" "$phase_name"
    printf "[${GREEN}%s${NC}${DIM}%s${NC}] %3d%%" \
           "$(printf "%${completed}s" | tr ' ' '=')" \
           "$(printf "%${remaining}s" | tr ' ' '-')" \
           "$percentage"
}

# Error handling with retry mechanism
execute_with_retry() {
    local cmd="$1"
    local description="$2"
    local retry_count=0
    local success=false
    
    while [[ $retry_count -lt $MAX_RETRIES ]]; do
        log "INFO" "Attempting: $description (attempt $((retry_count + 1))/$MAX_RETRIES)"
        
        if eval timeout "$TIMEOUT" $cmd; then
            log "SUCCESS" "Completed: $description"
            success=true
            break
        else
            local exit_code=$?
            log "WARN" "Failed: $description (exit code: $exit_code)"
            ((retry_count++))
            
            if [[ $retry_count -lt $MAX_RETRIES ]]; then
                log "INFO" "Retrying in 5 seconds..."
                sleep 5
            fi
        fi
    done
    
    if [[ "$success" == false ]]; then
        log "ERROR" "Failed after $MAX_RETRIES attempts: $description"
        ((ERROR_COUNT++))
        return 1
    fi
    
    return 0
}

# Resource monitoring
check_system_resources() {
    log "INFO" "Checking system resources..."
    
    # Check available memory
    local available_mem_gb=$(free -g | awk '/Mem:/ {print $7}')
    if [[ $available_mem_gb -lt $MAX_MEMORY_GB ]]; then
        log "WARN" "Low memory available: ${available_mem_gb}GB (recommended: ${MAX_MEMORY_GB}GB)"
        ((WARNING_COUNT++))
    fi
    
    # Check available disk space
    local available_disk_gb=$(df -BG . | awk 'NR==2 {print $4}' | tr -d 'G')
    if [[ $available_disk_gb -lt $MAX_DISK_SPACE_GB ]]; then
        log "WARN" "Low disk space available: ${available_disk_gb}GB (recommended: ${MAX_DISK_SPACE_GB}GB)"
        ((WARNING_COUNT++))
    fi
    
    log "INFO" "Memory: ${available_mem_gb}GB available, Disk: ${available_disk_gb}GB available"
}

# Tool version checking
check_tool_version() {
    local tool="$1"
    local min_version="$2"
    
    if ! command -v "$tool" >/dev/null 2>&1; then
        log "DEBUG" "Tool $tool not found"
        return 1
    fi
    
    local version=$($tool --version 2>/dev/null | head -n1 | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | head -n1)
    if [[ -z "$version" ]]; then
        log "DEBUG" "Could not determine version for $tool"
        return 0  # Assume it's OK if we can't check
    fi
    
    if ! python3 -c "from packaging import version; print(version.parse('$version') >= version.parse('$min_version'))" 2>/dev/null; then
        log "WARN" "$tool version $version is below minimum required $min_version"
        return 1
    fi
    
    log "DEBUG" "$tool version $version meets requirements"
    return 0
}

# =============================================================================
# TOOL INSTALLATION AND VERIFICATION
# =============================================================================

install_python_dependencies() {
    log "INFO" "Installing Python dependencies..."
    
    # Check if pip is available
    if ! command -v pip3 >/dev/null 2>&1; then
        log "WARN" "pip3 not available, skipping Python package installation"
        return 1
    fi
    
    # Install required Python packages
    local packages=("packaging" "requests" "yaml" "jinja2")
    
    for package in "${packages[@]}"; do
        if ! pip3 show "$package" >/dev/null 2>&1; then
            log "INFO" "Installing Python package: $package"
            pip3 install "$package" >/dev/null 2>&1 || log "WARN" "Failed to install $package"
        fi
    done
}

install_tool() {
    local tool="$1"
    local method="$2"
    
    log "INFO" "Installing $tool..."
    
    case "$method" in
        "curl")
            local url="$3"
            local dest="${4:-/usr/local/bin}"
            if execute_with_retry "curl -sSL '$url' -o '$dest/$tool'" "Download $tool"; then
                chmod +x "$dest/$tool"
                return 0
            fi
            ;;
        "brew")
            if execute_with_retry "brew install $tool" "Install $tool via Homebrew"; then
                return 0
            fi
            ;;
        "apt")
            if execute_with_retry "sudo apt update && sudo apt install -y $tool" "Install $tool via apt"; then
                return 0
            fi
            ;;
        "docker")
            local image="$3"
            if execute_with_retry "docker pull $image" "Pull Docker image for $tool"; then
                return 0
            fi
            ;;
        "git")
            local repo="$3"
            local dest="$4"
            if execute_with_retry "git clone '$repo' '$dest'" "Clone $tool repository"; then
                return 0
            fi
            ;;
        "helm")
            if execute_with_retry "helm install $tool $3" "Install $tool via Helm"; then
                return 0
            fi
            ;;
    esac
    
    return 1
}

verify_and_install_tools() {
    log "INFO" "Verifying and installing required tools..."
    
    # Core tools
    declare -A tools=(
        ["docker"]="Docker CLI"
        ["jq"]="JSON processor"
        ["tar"]="Archive utility"
        ["curl"]="Download utility"
        ["git"]="Version control"
    )
    
    # Check core tools first
    for tool in "${!tools[@]}"; do
        if ! command -v "$tool" >/dev/null 2>&1; then
            log "ERROR" "Required tool $tool (${tools[$tool]}) not found"
            exit 1
        fi
        log "DEBUG" "âœ“ $tool found"
    done
    
    # Install Python dependencies
    install_python_dependencies
    
    # Advanced tools with installation methods
    declare -A advanced_tools=(
        ["syft"]="curl|https://raw.githubusercontent.com/anchore/syft/main/install.sh|/usr/local/bin"
        ["grype"]="curl|https://raw.githubusercontent.com/anchore/grype/main/install.sh|/usr/local/bin"
        ["skopeo"]="brew|skopeo||apt|skopeo"
        ["crane"]="brew|crane||apt|crane"
        ["dive"]="brew|dive||apt|dive"
        ["kompose"]="curl|https://github.com/kubernetes/kompose/releases/latest/download/kompose-linux-amd64|/usr/local/bin"
        ["helm"]="curl|https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3"
    )
    
    for tool in "${!advanced_tools[@]}"; do
        IFS='|' read -ra methods <<< "${advanced_tools[$tool]}"
        
        if command -v "$tool" >/dev/null 2>&1; then
            log "DEBUG" "âœ“ $tool already installed"
            
            # Check version if applicable
            case "$tool" in
                "syft") check_tool_version "syft" "$MIN_SYFT_VERSION" && HAS_SYFT=true ;;
                "grype") check_tool_version "grype" "$MIN_GRYPE_VERSION" && HAS_GRYPE=true ;;
                "dive") check_tool_version "dive" "$MIN_DIVE_VERSION" && HAS_DIVE=true ;;
            esac
            
            continue
        fi
        
        log "INFO" "Installing $tool..."
        local installed=false
        
        for method in "${methods[@]}"; do
            case "$method" in
                "curl")
                    local url="${methods[1]}"
                    local dest="${methods[2]:-/usr/local/bin}"
                    if install_tool "$tool" "curl" "$url" "$dest"; then
                        installed=true
                        break
                    fi
                    ;;
                "brew")
                    if command -v brew >/dev/null 2>&1 && install_tool "$tool" "brew"; then
                        installed=true
                        break
                    fi
                    ;;
                "apt")
                    if command -v apt >/dev/null 2>&1 && install_tool "$tool" "apt"; then
                        installed=true
                        break
                    fi
                    ;;
            esac
        done
        
        if [[ "$installed" == true ]]; then
            log "SUCCESS" "âœ“ $tool installed successfully"
            
            # Set availability flags
            case "$tool" in
                "syft") HAS_SYFT=true ;;
                "grype") HAS_GRYPE=true ;;
                "dive") HAS_DIVE=true ;;
                "skopeo") HAS_SKOPEO=true ;;
                "crane") HAS_CRANE=true ;;
                "kompose") HAS_KOMPOSE=true ;;
                "helm") HAS_HELM=true ;;
            esac
        else
            log "WARN" "âš  Failed to install $tool, some features may be unavailable"
            ((WARNING_COUNT++))
        fi
    done
    
    # Check for optional advanced tools
    if command -v python3 >/dev/null 2>&1; then
        HAS_PYTHON3=true
        if pip3 show uncompyle6 >/dev/null 2>&1; then
            HAS_UNCOMPILE6=true
        fi
    fi
    
    if command -v volatility >/dev/null 2>&1; then
        HAS_VOLATILITY=true
    fi
    
    # Docker-based tools
    if docker images | grep -q "pegleg/whaler"; then
        HAS_WHALER=true
    elif [[ "$DEEP_SCAN" == true ]]; then
        log "INFO" "Pulling Whaler Docker image..."
        if docker pull pegleg/whaler >/dev/null 2>&1; then
            HAS_WHALER=true
        fi
    fi
    
    log "INFO" "Tool verification completed"
}

# =============================================================================
# PHASE IMPLEMENTATIONS
# =============================================================================

phase0_intelligence_reconnaissance() {
    CURRENT_PHASE="Intelligence & Registry Reconnaissance"
    PHASE_START_TIME=$(date +%s)
    show_progress 1 $TOTAL_PHASES "$CURRENT_PHASE"
    
    log "INFO" "Starting passive reconnaissance..."
    
    # Remote manifest inspection
    if [[ "$HAS_SKOPEO" == true ]]; then
        log "INFO" "Inspecting remote registry..."
        if execute_with_retry "skopeo inspect --raw 'docker://$IMAGE' | jq > '$OUTPUT_DIR/metadata/remote-manifest.json'" \
            "Remote manifest inspection"; then
            log "SUCCESS" "Remote manifest retrieved"
        fi
    fi
    
    # Image manifest
    if [[ "$HAS_CRANE" == true ]]; then
        log "INFO" "Retrieving image manifest..."
        if execute_with_retry "crane manifest '$IMAGE' > '$OUTPUT_DIR/metadata/manifest.json'" \
            "Image manifest retrieval"; then
            log "SUCCESS" "Image manifest retrieved"
        fi
    fi
    
    # Registry metadata
    if [[ "$HAS_SKOPEO" == true ]]; then
        log "INFO" "Gathering registry metadata..."
        if execute_with_retry "skopeo inspect 'docker://$IMAGE' | jq > '$OUTPUT_DIR/metadata/registry-info.json'" \
            "Registry metadata gathering"; then
            log "SUCCESS" "Registry metadata retrieved"
        fi
    fi
    
    # Image size and layer analysis
    if [[ -f "$OUTPUT_DIR/metadata/manifest.json" ]]; then
        log "INFO" "Analyzing manifest structure..."
        local layer_count=$(jq '.layers | length' "$OUTPUT_DIR/metadata/manifest.json" 2>/dev/null || echo "0")
        log "INFO" "Image contains $layer_count layers"
    fi
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 0 completed${NC}"
}

phase1_secure_acquisition() {
    CURRENT_PHASE="Secure Image Acquisition"
    PHASE_START_TIME=$(date +%s)
    show_progress 2 $TOTAL_PHASES "$CURRENT_PHASE"
    
    log "INFO" "Starting secure image acquisition..."
    
    # Pull image
    log "INFO" "Pulling image: $IMAGE"
    if execute_with_retry "docker pull '$IMAGE'" "Image pull"; then
        log "SUCCESS" "Image pulled successfully"
    else
        log "ERROR" "Failed to pull image"
        exit 1
    fi
    
    # Save image archive
    log "INFO" "Creating image archive..."
    if execute_with_retry "docker save '$IMAGE' -o '$OUTPUT_DIR/metadata/image.tar'" "Image archive creation"; then
        log "SUCCESS" "Image archive created"
    fi
    
    # Extract image archive for layer analysis
    log "INFO" "Extracting image archive..."
    if execute_with_retry "tar -xf '$OUTPUT_DIR/metadata/image.tar' -C '$OUTPUT_DIR/metadata'" \
        "Archive extraction"; then
        log "SUCCESS" "Image archive extracted"
    fi
    
    # Get image metadata
    log "INFO" "Extracting image metadata..."
    docker inspect "$IMAGE" | jq > "$OUTPUT_DIR/metadata/image-inspect.json"
    log "SUCCESS" "Image metadata extracted"
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 1 completed${NC}"
}

phase1_5_dockerfile_reconstruction() {
    CURRENT_PHASE="Dockerfile Reconstruction"
    PHASE_START_TIME=$(date +%s)
    show_progress 3 $TOTAL_PHASES "$CURRENT_PHASE"
    
    log "INFO" "Starting Dockerfile reconstruction..."
    
    # Method 1: Whaler (most accurate)
    if [[ "$HAS_WHALER" == true ]]; then
        log "INFO" "Using Whaler for Dockerfile reconstruction..."
        if execute_with_retry "docker run -v /var/run/docker.sock:/var/run/docker.sock:ro \
            pegleg/whaler -sV=1.36 '$IMAGE' > '$OUTPUT_DIR/dockerfile/Dockerfile.whaler'" \
            "Whaler reconstruction"; then
            log "SUCCESS" "Dockerfile reconstructed via Whaler"
        fi
    fi
    
    # Method 2: dfimage (Python-based)
    log "INFO" "Using dfimage for Dockerfile reconstruction..."
    if execute_with_retry "docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
        alpine/dfimage -sV=1.36 '$IMAGE' > '$OUTPUT_DIR/dockerfile/Dockerfile.dfimage'" \
        "dfimage reconstruction"; then
        log "SUCCESS" "Dockerfile reconstructed via dfimage"
    fi
    
    # Method 3: Docker history parsing (always available)
    log "INFO" "Parsing Docker history..."
    docker history --no-trunc "$IMAGE" > "$OUTPUT_DIR/dockerfile/history.raw"
    
    # Advanced parsing technique
    docker history --no-trunc "$IMAGE" | \
        awk '{$1=$2=$3=$4=""; print $0}' | \
        grep -v COMMENT | \
        nl | \
        sort -nr | \
        sed 's/^[^A-Z]*//' | \
        sed -E 's/[0-9]+(\.[0-9]+)?(B|KB|MB|GB|kB)[[:space:]].*//g' > "$OUTPUT_DIR/dockerfile/Dockerfile.reconstructed"
    
    log "SUCCESS" "Dockerfile reconstructed via history parsing"
    
    # Select best reconstruction
    local best_file=""
    if [[ -f "$OUTPUT_DIR/dockerfile/Dockerfile.whaler" ]] && [[ -s "$OUTPUT_DIR/dockerfile/Dockerfile.whaler" ]]; then
        best_file="Dockerfile.whaler"
    elif [[ -f "$OUTPUT_DIR/dockerfile/Dockerfile.dfimage" ]] && [[ -s "$OUTPUT_DIR/dockerfile/Dockerfile.dfimage" ]]; then
        best_file="Dockerfile.dfimage"
    else
        best_file="Dockerfile.reconstructed"
    fi
    
    cp "$OUTPUT_DIR/dockerfile/$best_file" "$OUTPUT_DIR/Dockerfile.reconstructed"
    log "INFO" "Best reconstruction selected: $best_file"
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 1.5 completed${NC}"
}

phase2_binary_forensics() {
    CURRENT_PHASE="Binary Forensics Analysis"
    PHASE_START_TIME=$(date +%s)
    show_progress 4 $TOTAL_PHASES "$CURRENT_PHASE"
    
    log "INFO" "Starting binary forensics analysis..."
    
    # Extract binary information
    log "INFO" "Identifying binary files..."
    find "$OUTPUT_DIR/filesystem" -type f -executable -exec file {} \; | \
        grep -E "(ELF|executable|binary)" > "$OUTPUT_DIR/analysis/binaries.txt" 2>/dev/null || true
    
    local binary_count=$(wc -l < "$OUTPUT_DIR/analysis/binaries.txt" 2>/dev/null || echo "0")
    log "INFO" "Found $binary_count binary files"
    
    # Extract strings from binaries for analysis
    if [[ "$DEEP_SCAN" == true ]]; then
        log "INFO" "Extracting strings from binaries (deep scan)..."
        while IFS= read -r -d '' binary; do
            local rel_path="${binary#$OUTPUT_DIR/filesystem/}"
            strings "$binary" | head -100 > "$OUTPUT_DIR/analysis/strings_${rel_path//\//_}.txt" 2>/dev/null || true
        done < <(find "$OUTPUT_DIR/filesystem" -type f -executable -print0 2>/dev/null | head -10)
    fi
    
    # Check for Go binaries specifically
    log "INFO" "Identifying Go binaries..."
    find "$OUTPUT_DIR/filesystem" -type f -executable -exec sh -c 'file "$1" | grep -q "Go BuildID" && echo "$1"' _ {} \; \
        > "$OUTPUT_DIR/analysis/go-binaries.txt" 2>/dev/null || true
    
    # Check for UPX-packed binaries
    log "INFO" "Checking for UPX-packed binaries..."
    find "$OUTPUT_DIR/filesystem" -type f -executable -exec sh -c 'strings "$1" | grep -q "UPX" && echo "$1"' _ {} \; \
        > "$OUTPUT_DIR/analysis/upx-packed.txt" 2>/dev/null || true
    
    log "INFO" "Binary forensics analysis completed"
    log "WARN" "Advanced binary analysis requires manual tools like Ghidra/Cutter"
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 2 completed${NC}"
}

phase2_5_filesystem_extraction() {
    CURRENT_PHASE="Complete Filesystem Extraction"
    PHASE_START_TIME=$(date +%s)
    show_progress 5 $TOTAL_PHASES "$CURRENT_PHASE"
    
    log "INFO" "Starting filesystem extraction..."
    
    # Method 1: Docker build output (recommended)
    log "INFO" "Extracting filesystem via Docker build..."
    if execute_with_retry "docker build --output type=local,dest='$OUTPUT_DIR/filesystem' - <<< 'FROM $IMAGE'" \
        "Filesystem extraction via build"; then
        log "SUCCESS" "Filesystem extracted via build method"
    else
        # Fallback method
        log "INFO" "Using fallback extraction method..."
        local temp_container=$(docker create "$IMAGE")
        if execute_with_retry "docker export '$temp_container' | tar -xf - -C '$OUTPUT_DIR/filesystem'" \
            "Filesystem export"; then
            log "SUCCESS" "Filesystem extracted via export"
        fi
        docker rm "$temp_container" >/dev/null 2>&1 || true
    fi
    
    # Layer-by-layer extraction
    log "INFO" "Extracting individual layers..."
    if [[ -f "$OUTPUT_DIR/metadata/manifest.json" ]]; then
        cd "$OUTPUT_DIR/metadata"
        for layer_tar in */layer.tar; do
            if [[ -f "$layer_tar" ]]; then
                layer_dir="${layer_tar%.tar}"
                mkdir -p "../layers/$layer_dir"
                if execute_with_retry "tar -xf '$layer_tar' -C '../layers/$layer_dir'" "Layer extraction: $layer_dir"; then
                    log "DEBUG" "Extracted layer: $layer_dir"
                fi
            fi
        done
        cd - >/dev/null
    fi
    
    # Filesystem analysis
    log "INFO" "Analyzing filesystem structure..."
    local total_files=$(find "$OUTPUT_DIR/filesystem" -type f | wc -l 2>/dev/null || echo "0")
    local total_dirs=$(find "$OUTPUT_DIR/filesystem" -type d | wc -l 2>/dev/null || echo "0")
    local filesystem_size=$(du -sh "$OUTPUT_DIR/filesystem" 2>/dev/null | cut -f1 || echo "unknown")
    
    log "INFO" "Filesystem stats: $total_files files, $total_dirs directories, $filesystem_size"
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 2.5 completed${NC}"
}

phase3_config_recovery() {
    CURRENT_PHASE="Configuration Recovery"
    PHASE_START_TIME=$(date +%s)
    show_progress 6 $TOTAL_PHASES "$CURRENT_PHASE"
    
    log "INFO" "Starting configuration recovery..."
    
    # Extract image configuration
    log "INFO" "Extracting image configuration..."
    docker inspect "$IMAGE" | jq > "$OUTPUT_DIR/configs/image-config.json"
    
    # Extract specific configurations
    log "INFO" "Extracting environment variables..."
    docker inspect "$IMAGE" | jq -r '.[0].Config.Env[]' > "$OUTPUT_DIR/configs/environment.txt
    
    log "INFO" "Extracting exposed ports..."
    docker inspect "$IMAGE" | jq '.[0].Config.ExposedPorts' > "$OUTPUT_DIR/configs/ports.json
    
    log "INFO" "Extracting volumes..."
    docker inspect "$IMAGE" | jq '.[0].Config.Volumes' > "$OUTPUT_DIR/configs/volumes.json
    
    log "INFO" "Extracting labels..."
    docker inspect "$IMAGE" | jq '.[0].Config.Labels' > "$OUTPUT_DIR/configs/labels.json
    
    # Extract working directory
    log "INFO" "Extracting working directory..."
    docker inspect "$IMAGE" | jq -r '.[0].Config.WorkingDir' > "$OUTPUT_DIR/configs/workingdir.txt
    
    # Extract user information
    log "INFO" "Extracting user information..."
    docker inspect "$IMAGE" | jq -r '.[0].Config.User' > "$OUTPUT_DIR/configs/user.txt
    
    # Extract entrypoint and command
    log "INFO" "Extracting entrypoint and command..."
    docker inspect "$IMAGE" | jq '.[0].Config.Entrypoint' > "$OUTPUT_DIR/configs/entrypoint.json
    docker inspect "$IMAGE" | jq '.[0].Config.Cmd' > "$OUTPUT_DIR/configs/cmd.json
    
    # Find configuration files in filesystem
    log "INFO" "Scanning for configuration files..."
    find "$OUTPUT_DIR/filesystem" -name "*.conf" -o -name "*.config" -o -name "*.ini" -o -name "*.yaml" -o -name "*.yml" -o -name "*.toml" -o -name "*.json" | \
        head -50 > "$OUTPUT_DIR/configs/config-files.txt" 2>/dev/null || true
    
    # Categorize configuration files
    log "INFO" "Categorizing configuration files..."
    while IFS= read -r config_file; do
        local filename=$(basename "$config_file")
        case "$filename" in
            *nginx*|*apache*|*httpd*)
                cp "$config_file" "$OUTPUT_DIR/configs/webserver/" 2>/dev/null || true
                ;;
            *mysql*|*postgres*|*redis*|*mongodb*)
                cp "$config_file" "$OUTPUT_DIR/configs/database/" 2>/dev/null || true
                ;;
            *app*|*application*|*service*)
                cp "$config_file" "$OUTPUT_DIR/configs/application/" 2>/dev/null || true
                ;;
        esac
    done < "$OUTPUT_DIR/configs/config-files.txt" 2>/dev/null || true
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 3 completed${NC}"
}

phase3_5_compose_reconstruction() {
    CURRENT_PHASE="Docker Compose Reconstruction"
    PHASE_START_TIME=$(date +%s)
    show_progress 7 $TOTAL_PHASES "$CURRENT_PHASE"
    
    log "INFO" "Starting Docker Compose reconstruction..."
    
    # Generate docker-compose.yml from image configuration
    log "INFO" "Generating docker-compose.yml..."
    
    # Service name sanitization
    local service_name=$(echo "$IMAGE" | tr ':/' '__' | tr '[:upper:]' '[:lower:]')
    
    cat > "$OUTPUT_DIR/compose/docker-compose.yml" << EOF
version: '3.8'
services:
  $service_name:
    image: $IMAGE
    container_name: $service_name
EOF
    
    # Add working directory if specified
    if [[ -s "$OUTPUT_DIR/configs/workingdir.txt" ]] && [[ $(cat "$OUTPUT_DIR/configs/workingdir.txt") != "null" ]]; then
        echo "    working_dir: $(cat "$OUTPUT_DIR/configs/workingdir.txt")" >> "$OUTPUT_DIR/compose/docker-compose.yml"
    fi
    
    # Add user if specified
    if [[ -s "$OUTPUT_DIR/configs/user.txt" ]] && [[ $(cat "$OUTPUT_DIR/configs/user.txt") != "null" ]]; then
        echo "    user: $(cat "$OUTPUT_DIR/configs/user.txt")" >> "$OUTPUT_DIR/compose/docker-compose.yml"
    fi
    
    # Add environment variables
    if [[ -s "$OUTPUT_DIR/configs/environment.txt" ]]; then
        echo "    environment:" >> "$OUTPUT_DIR/compose/docker-compose.yml"
        while IFS= read -r env_var; do
            echo "      - $env_var" >> "$OUTPUT_DIR/compose/docker-compose.yml"
        done < "$OUTPUT_DIR/configs/environment.txt"
    fi
    
    # Add ports
    if [[ -s "$OUTPUT_DIR/configs/ports.json" ]] && [[ $(jq length "$OUTPUT_DIR/configs/ports.json" 2>/dev/null || echo "0") -gt 0 ]]; then
        echo "    ports:" >> "$OUTPUT_DIR/compose/docker-compose.yml"
        jq -r 'keys[]' "$OUTPUT_DIR/configs/ports.json" 2>/dev/null | while read -r port; do
            # Clean up port specification
            local clean_port=$(echo "$port" | sed 's/\/tcp$//' | sed 's/\/udp$//')
            echo "      - \"$clean_port:$clean_port\"" >> "$OUTPUT_DIR/compose/docker-compose.yml"
        done
    fi
    
    # Add volumes
    if [[ -s "$OUTPUT_DIR/configs/volumes.json" ]] && [[ $(jq length "$OUTPUT_DIR/configs/volumes.json" 2>/dev/null || echo "0") -gt 0 ]]; then
        echo "    volumes:" >> "$OUTPUT_DIR/compose/docker-compose.yml"
        jq -r 'keys[]' "$OUTPUT_DIR/configs/volumes.json" 2>/dev/null | while read -r volume; do
            echo "      - $volume:$volume" >> "$OUTPUT_DIR/compose/docker-compose.yml"
        done
    fi
    
    # Add entrypoint and command if specified
    if [[ -s "$OUTPUT_DIR/configs/entrypoint.json" ]] && [[ $(jq length "$OUTPUT_DIR/configs/entrypoint.json" 2>/dev/null || echo "0") -gt 0 ]]; then
        echo "    entrypoint: $(jq -c '.' "$OUTPUT_DIR/configs/entrypoint.json" 2>/dev/null)" >> "$OUTPUT_DIR/compose/docker-compose.yml"
    fi
    
    if [[ -s "$OUTPUT_DIR/configs/cmd.json" ]] && [[ $(jq length "$OUTPUT_DIR/configs/cmd.json" 2>/dev/null || echo "0") -gt 0 ]]; then
        echo "    command: $(jq -c '.' "$OUTPUT_DIR/configs/cmd.json" 2>/dev/null)" >> "$OUTPUT_DIR/compose/docker-compose.yml"
    fi
    
    log "SUCCESS" "docker-compose.yml generated"
    
    # Check for Kubernetes conversion if Kompose is available
    if [[ "$HAS_KOMPOSE" == true ]]; then
        log "INFO" "Converting to Kubernetes manifests..."
        if execute_with_retry "kompose convert -f '$OUTPUT_DIR/compose/docker-compose.yml' -o '$OUTPUT_DIR/orchestration/'" \
            "Kubernetes conversion"; then
            log "SUCCESS" "Kubernetes manifests generated"
        fi
    fi
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 3.5 completed${NC}"
}

phase4_sbom_vulnerability() {
    CURRENT_PHASE="SBOM & Vulnerability Analysis"
    PHASE_START_TIME=$(date +%s)
    show_progress 8 $TOTAL_PHASES "$CURRENT_PHASE"
    
    log "INFO" "Starting SBOM generation and vulnerability analysis..."
    
    # Generate SBOM
    if [[ "$HAS_SYFT" == true ]]; then
        log "INFO" "Generating SBOM..."
        if execute_with_retry "syft '$IMAGE' -o spdx-json='$OUTPUT_DIR/sbom/sbom.json'" \
            "SBOM generation"; then
            log "SUCCESS" "SBOM generated successfully"
            
            # Generate human-readable format
            syft "$IMAGE" -o table > "$OUTPUT_DIR/sbom/packages.txt" 2>/dev/null || true
            
            # Generate CycloneDX format
            syft "$IMAGE" -o cyclonedx-json="$OUTPUT_DIR/sbom/sbom-cyclonedx.json" 2>/dev/null || true
            
            # Analyze SBOM
            log "INFO" "Analyzing SBOM..."
            local package_count=$(jq '.artifacts | length' "$OUTPUT_DIR/sbom/sbom.json" 2>/dev/null || echo "0")
            log "INFO" "SBOM contains $package_count packages"
            
            # Extract package types
            jq -r '.artifacts[].type' "$OUTPUT_DIR/sbom/sbom.json" 2>/dev/null | sort | uniq -c > "$OUTPUT_DIR/sbom/package-types.txt" 2>/dev/null || true
        fi
    fi
    
    # Vulnerability scanning
    if [[ "$HAS_GRYPE" == true ]] && [[ -f "$OUTPUT_DIR/sbom/sbom.json" ]]; then
        log "INFO" "Scanning for vulnerabilities..."
        if execute_with_retry "grype sbom:'$OUTPUT_DIR/sbom/sbom.json' -o json > '$OUTPUT_DIR/vulnerabilities/vulnerabilities.json'" \
            "Vulnerability scanning"; then
            log "SUCCESS" "Vulnerability scan completed"
            
            # Generate summary
            grype sbom:"$OUTPUT_DIR/sbom/sbom.json" -o table > "$OUTPUT_DIR/vulnerabilities/summary.txt" 2>/dev/null || true
            
            # Analyze vulnerabilities
            local vuln_count=$(jq '.matches | length' "$OUTPUT_DIR/vulnerabilities/vulnerabilities.json" 2>/dev/null || echo "0")
            log "INFO" "Found $vuln_count vulnerabilities"
            
            # Categorize by severity
            jq -r '.matches[].vulnerability.severity' "$OUTPUT_DIR/vulnerabilities/vulnerabilities.json" 2>/dev/null | \
                sort | uniq -c > "$OUTPUT_DIR/vulnerabilities/severity-distribution.txt" 2>/dev/null || true
        fi
    fi
    
    # Additional scanning with Dive if available
    if [[ "$HAS_DIVE" == true ]]; then
        log "INFO" "Running Dive analysis..."
        if execute_with_retry "dive '$IMAGE' --json > '$OUTPUT_DIR/analysis/dive-analysis.json'" \
            "Dive analysis"; then
            log "SUCCESS" "Dive analysis completed"
        fi
    fi
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 4 completed${NC}"
}

phase4_5_forensic_recovery() {
    CURRENT_PHASE="Forensic Artifact Recovery"
    PHASE_START_TIME=$(date +%s)
    show_progress 9 $TOTAL_PHASES "$CURRENT_PHASE"
    
    log "INFO" "Starting forensic artifact recovery..."
    
    # Enhanced secret scanning
    log "INFO" "Scanning for secrets and credentials..."
    
    # Common secret patterns
    local secret_patterns=(
        "password[[:space:]]*=[[:space:]]*[^[:space:]]+"
        "secret[[:space:]]*=[[:space:]]*[^[:space:]]+"
        "api[_-]?key[[:space:]]*=[[:space:]]*[^[:space:]]+"
        "token[[:space:]]*=[[:space:]]*[^[:space:]]+"
        "private[_-]?key"
        "BEGIN.*PRIVATE KEY"
        "BEGIN.*RSA PRIVATE KEY"
        "aws[_-]?access[_-]?key[_-]?id"
        "aws[_-]?secret[_-]?access[_-]?key"
        "github[_-]?token"
        "slack[_-]?token"
        "database[_-]?url"
        "jdbc:"
        "mongodb://"
        "redis://"
        "postgresql://"
        "mysql://"
    )
    
    # Scan for secrets
    for pattern in "${secret_patterns[@]}"; do
        grep -r -i -E "$pattern" "$OUTPUT_DIR/filesystem" 2>/dev/null | \
            head -5 >> "$OUTPUT_DIR/forensic/secrets-found.txt" || true
    done
    
    # Remove duplicates
    sort -u "$OUTPUT_DIR/forensic/secrets-found.txt" 2>/dev/null > "${OUTPUT_DIR}/forensic/secrets-found.tmp" 2>/dev/null || true
    mv "${OUTPUT_DIR}/forensic/secrets-found.tmp" "$OUTPUT_DIR/forensic/secrets-found.txt" 2>/dev/null || true
    
    # Certificate discovery
    log "INFO" "Discovering certificates..."
    find "$OUTPUT_DIR/filesystem" -name "*.pem" -o -name "*.crt" -o -name "*.key" -o -name "*.jks" -o -name "*.p12" -o -name "*.pfx" | \
        head -20 > "$OUTPUT_DIR/forensic/certificates.txt" 2>/dev/null || true
    
    # SSH keys
    log "INFO" "Finding SSH keys..."
    find "$OUTPUT_DIR/filesystem" -name "id_rsa" -o -name "id_ed25519" -o -name "id_dsa" -o -name "id_ecdsa" -o -name "authorized_keys" -o -name "known_hosts" | \
        head -10 > "$OUTPUT_DIR/forensic/ssh-keys.txt" 2>/dev/null || true
    
    # Configuration files with potential credentials
    log "INFO" "Identifying credential files..."
    find "$OUTPUT_DIR/filesystem" -name ".env*" -o -name "credentials*" -o -name "config*" -o -name "secret*" -o -name "pass*" | \
        grep -E "\.(env|credentials|config|secret|pass)$" | head -15 > "$OUTPUT_DIR/forensic/credential-files.txt" 2>/dev/null || true
    
    # Database configuration files
    log "INFO" "Finding database configurations..."
    find "$OUTPUT_DIR/filessystem" -name "my.cnf" -o -name "postgresql.conf" -o -name "redis.conf" -o -name "mongod.conf" -o -name "database.yml" | \
        head -10 > "$OUTPUT_DIR/forensic/database-configs.txt" 2>/dev/null || true
    
    # Docker Forensics Toolkit (if available and enabled)
    if [[ "$ENABLE_FORENSICS" == true ]] && [[ "$HAS_PYTHON3" == true ]]; then
        log "INFO" "Running Docker Forensics Toolkit..."
        
        # Clone toolkit if not present
        if [[ ! -d "docker-forensics-toolkit" ]]; then
            log "INFO" "Cloning Docker Forensics Toolkit..."
            if execute_with_retry "git clone https://github.com/docker-forensics-toolkit/toolkit.git" \
                "Clone Docker Forensics Toolkit"; then
                log "SUCCESS" "Docker Forensics Toolkit cloned"
            fi
        fi
        
        # Run forensic analysis
        if [[ -d "docker-forensics-toolkit" ]]; then
            log "INFO" "Running forensic carving..."
            python3 docker-forensics-toolkit/src/dof/carve-for-deleted-docker-files.py /var/lib/docker 2>/dev/null | \
                head -20 > "$OUTPUT_DIR/forensic/carved-files.txt" || true
            
            log "INFO" "Extracting container configurations..."
            if [[ -n "$CONTAINER_ID" ]]; then
                python3 docker-forensics-toolkit/src/dof/show-container-config.py "$CONTAINER_ID" 2>/dev/null > \
                    "$OUTPUT_DIR/forensic/container-config-detailed.json" || true
            fi
        fi
    fi
    
    # Summary of findings
    local secret_count=$(wc -l < "$OUTPUT_DIR/forensic/secrets-found.txt" 2>/dev/null || echo "0")
    local cert_count=$(wc -l < "$OUTPUT_DIR/forensic/certificates.txt" 2>/dev/null || echo "0")
    local ssh_count=$(wc -l < "$OUTPUT_DIR/forensic/ssh-keys.txt" 2>/dev/null || echo "0")
    
    log "INFO" "Forensic summary: $secret_count potential secrets, $cert_count certificates, $ssh_count SSH keys"
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 4.5 completed${NC}"
}

phase5_runtime_analysis() {
    CURRENT_PHASE="Runtime Analysis"
    PHASE_START_TIME=$(date +%s)
    show_progress 10 $TOTAL_PHASES "$CURRENT_PHASE"
    
    if [[ "$SKIP_RUNTIME" == true ]]; then
        log "INFO" "Skipping runtime analysis (disabled)"
        ((COMPLETED_PHASES++))
        echo -e "\n${YELLOW}âš  Phase 5 skipped${NC}"
        return
    fi
    
    log "INFO" "Starting runtime analysis..."
    
    # Create runtime analysis script
    cat > "$OUTPUT_DIR/runtime/runtime-analysis.sh" << EOF
#!/bin/bash
# Runtime Analysis Script for $IMAGE

echo "Starting runtime analysis..."

# Create and start container
CONTAINER_NAME="runtime-analysis-$(date +%s)"
docker run -d --name "\$CONTAINER_NAME" "$IMAGE"

# Wait for container to be ready
sleep 10

# Container monitoring
echo "Collecting container stats..."
docker stats --no-stream "\$CONTAINER_NAME" > runtime-stats.txt

# Process information
echo "Collecting process information..."
docker top "\$CONTAINER_NAME" > runtime-processes.txt

# Network connections
echo "Collecting network information..."
docker exec "\$CONTAINER_NAME" netstat -tulpn 2>/dev/null > runtime-network.txt || true

# System information
echo "Collecting system information..."
docker exec "\$CONTAINER_NAME" uname -a 2>/dev/null > runtime-system.txt || true

# Running processes detail
echo "Collecting detailed process information..."
docker exec "\$CONTAINER_NAME" ps aux 2>/dev/null > runtime-ps.txt || true

# Open files
echo "Collecting open files information..."
docker exec "\$CONTAINER_NAME" lsof 2>/dev/null > runtime-lsof.txt || true

# Memory usage
echo "Collecting memory usage..."
docker exec "\$CONTAINER_NAME" free -m 2>/dev/null > runtime-memory.txt || true

# Disk usage
echo "Collecting disk usage..."
docker exec "\$CONTAINER_NAME" df -h 2>/dev/null > runtime-disk.txt || true

# Clean up
docker stop "\$CONTAINER_NAME"
docker rm "\$CONTAINER_NAME"

echo "Runtime analysis completed."
EOF
    
    chmod +x "$OUTPUT_DIR/runtime/runtime-analysis.sh"
    
    # If container ID is provided, analyze running container
    if [[ -n "$CONTAINER_ID" ]] && docker ps -q --filter "id=$CONTAINER_ID" | grep -q .; then
        log "INFO" "Analyzing running container: $CONTAINER_ID"
        
        # Container stats
        docker stats --no-stream "$CONTAINER_ID" > "$OUTPUT_DIR/runtime/container-stats.txt" 2>/dev/null || true
        
        # Process information
        docker top "$CONTAINER_ID" > "$OUTPUT_DIR/runtime/container-processes.txt" 2>/dev/null || true
        
        # Container logs
        docker logs "$CONTAINER_ID" > "$OUTPUT_DIR/runtime/container-logs.txt" 2>/dev/null || true
        
        # Container changes
        docker diff "$CONTAINER_ID" > "$OUTPUT_DIR/runtime/container-changes.txt" 2>/dev/null || true
        
        # Container inspect
        docker inspect "$CONTAINER_ID" > "$OUTPUT_DIR/runtime/container-inspect.json" 2>/dev/null || true
        
        # Network information
        docker exec "$CONTAINER_ID" netstat -tulpn 2>/dev/null > "$OUTPUT_DIR/runtime/container-network.txt" || true
        
        log "SUCCESS" "Runtime analysis completed for container $CONTAINER_ID"
    else
        log "INFO" "Runtime analysis script created. Run manually: $OUTPUT_DIR/runtime/runtime-analysis.sh"
    fi
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 5 completed${NC}"
}

phase6_offensive_security() {
    CURRENT_PHASE="Offensive Security Analysis"
    PHASE_START_TIME=$(date +%s)
    show_progress 11 $TOTAL_PHASES "$CURRENT_PHASE"
    
    if [[ "$SKIP_OFFENSIVE" == true ]]; then
        log "INFO" "Skipping offensive security analysis (disabled)"
        ((COMPLETED_PHASES++))
        echo -e "\n${YELLOW}âš  Phase 6 skipped${NC}"
        return
    fi
    
    log "INFO" "Starting offensive security analysis..."
    
    # Basic security checks
    log "INFO" "Performing basic security checks..."
    
    # Check for privileged containers
    if docker inspect "$IMAGE" | jq -r '.[0].Config.Privileged' | grep -q "true"; then
        echo "CRITICAL: Container runs as privileged" >> "$OUTPUT_DIR/security/security-issues.txt"
        log "ERROR" "Container runs as privileged"
        ((ERROR_COUNT++))
    fi
    
    # Check for root user
    local user=$(docker inspect "$IMAGE" | jq -r '.[0].Config.User')
    if [[ "$user" == "root" ]] || [[ "$user" == "0" ]] || [[ "$user" == "null" ]]; then
        echo "WARNING: Container runs as root user" >> "$OUTPUT_DIR/security/security-issues.txt"
        log "WARN" "Container runs as root user"
        ((WARNING_COUNT++))
    fi
    
    # Check for dangerous capabilities
    log "INFO" "Checking container capabilities..."
    docker inspect "$IMAGE" | jq -r '.[0].Config.CapAdd[]' 2>/dev/null | while read -r cap; do
        case "$cap" in
            "CAP_SYS_ADMIN"|"CAP_SYS_PTRACE"|"CAP_SYS_MODULE"|"CAP_DAC_READ_SEARCH"|"CAP_NET_ADMIN")
                echo "WARNING: Container has dangerous capability: $cap" >> "$OUTPUT_DIR/security/security-issues.txt"
                log "WARN" "Container has dangerous capability: $cap"
                ((WARNING_COUNT++))
                ;;
        esac
    done
    
    # Check for sensitive mounts
    log "INFO" "Checking for sensitive mounts..."
    docker inspect "$IMAGE" | jq -r '.[0].Config.Volumes | keys[]' 2>/dev/null | while read -r volume; do
        case "$volume" in
            "/etc"|"/var/run/docker.sock"|"/var/lib/docker"|"/root"|"/home")
                echo "WARNING: Container mounts sensitive directory: $volume" >> "$OUTPUT_DIR/security/security-issues.txt"
                log "WARN" "Container mounts sensitive directory: $volume"
                ((WARNING_COUNT++))
                ;;
        esac
    done
    
    # Check for network mode
    local network_mode=$(docker inspect "$IMAGE" | jq -r '.[0].Config.NetworkMode')
    if [[ "$network_mode" == "host" ]]; then
        echo "CRITICAL: Container uses host network mode" >> "$OUTPUT_DIR/security/security-issues.txt"
        log "ERROR" "Container uses host network mode"
        ((ERROR_COUNT++))
    fi
    
    # Check for PID mode
    local pid_mode=$(docker inspect "$IMAGE" | jq -r '.[0].Config.PidMode')
    if [[ "$pid_mode" == "host" ]]; then
        echo "CRITICAL: Container uses host PID mode" >> "$OUTPUT_DIR/security/security-issues.txt"
        log "ERROR" "Container uses host PID mode"
        ((ERROR_COUNT++))
    fi
    
    # Check for IPC mode
    local ipc_mode=$(docker inspect "$IMAGE" | jq -r '.[0].Config.IpcMode')
    if [[ "$ipc_mode" == "host" ]]; then
        echo "WARNING: Container uses host IPC mode" >> "$OUTPUT_DIR/security/security-issues.txt"
        log "WARN" "Container uses host IPC mode"
        ((WARNING_COUNT++))
    fi
    
    # Check for seccomp profile
    local seccomp_profile=$(docker inspect "$IMAGE" | jq -r '.[0].Config.SecurityOpt[] | select(contains("seccomp"))' 2>/dev/null)
    if [[ -z "$seccomp_profile" ]]; then
        echo "INFO: No custom seccomp profile detected" >> "$OUTPUT_DIR/security/security-issues.txt
    fi
    
    # Check for apparmor profile
    local apparmor_profile=$(docker inspect "$IMAGE" | jq -r '.[0].Config.SecurityOpt[] | select(contains("apparmor"))' 2>/dev/null)
    if [[ -z "$apparmor_profile" ]]; then
        echo "INFO: No custom AppArmor profile detected" >> "$OUTPUT_DIR/security/security-issues.txt
    fi
    
    # Check for read-only root filesystem
    local read_only=$(docker inspect "$IMAGE" | jq -r '.[0].Config.ReadonlyRootfs')
    if [[ "$read_only" != "true" ]]; then
        echo "INFO: Root filesystem is not read-only" >> "$OUTPUT_DIR/security/security-issues.txt
    fi
    
    # Check for health check
    local health_check=$(docker inspect "$IMAGE" | jq -r '.[0].Config.Healthcheck')
    if [[ "$health_check" == "null" ]]; then
        echo "INFO: No health check configured" >> "$OUTPUT_DIR/security/security-issues.txt
    fi
    
    # Generate security report
    log "INFO" "Generating security report..."
    cat > "$OUTPUT_DIR/security/security-summary.md" << EOF
# Security Analysis Report

## Container Configuration Security

### Critical Issues
 $(grep -i "critical:" "$OUTPUT_DIR/security/security-issues.txt" 2>/dev/null || echo "None")

### Warnings
 $(grep -i "warning:" "$OUTPUT_DIR/security/security-issues.txt" 2>/dev/null || echo "None")

### Informational
 $(grep -i "info:" "$OUTPUT_DIR/security/security-issues.txt" 2>/dev/null || echo "None")

## Security Recommendations

1. **Least Privilege**: Run containers as non-root user
2. **Resource Limits**: Set memory and CPU limits
3. **Read-only Filesystem**: Use read-only root filesystem when possible
4. **Capabilities**: Drop unnecessary capabilities
5. **Security Profiles**: Use seccomp and AppArmor profiles
6. **Network Isolation**: Avoid host network mode
7. **Health Checks**: Implement health checks for reliability

---
*Generated by Ultimate Docker Decomposition Framework*
EOF
    
    log "SUCCESS" "Offensive security analysis completed"
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 6 completed${NC}"
}

phase6_5_source_recovery() {
    CURRENT_PHASE="Source Code Recovery"
    PHASE_START_TIME=$(date +%s)
    show_progress 12 $TOTAL_PHASES "$CURRENT_PHASE"
    
    log "INFO" "Starting source code recovery..."
    
    # Find application directories
    log "INFO" "Discovering application directories..."
    
    # Common application locations
    local app_dirs=("/app" "/src" "/usr/src/app" "/opt/app" "/var/www" "/home/app" "/application" "/code")
    
    for app_dir in "${app_dirs[@]}"; do
        if [[ -d "$OUTPUT_DIR/filesystem$app_dir" ]]; then
            log "INFO" "Found application directory: $app_dir"
            local dir_name=$(basename "$app_dir")
            cp -r "$OUTPUT_DIR/filesystem$app_dir" "$OUTPUT_DIR/source/$dir_name" 2>/dev/null || true
        fi
    done
    
    # Language-specific discovery and recovery
    log "INFO" "Language-specific source discovery..."
    
    # Python applications
    log "INFO" "Recovering Python source code..."
    find "$OUTPUT_DIR/filesystem" -name "*.py" -o -name "requirements.txt" -o -name "setup.py" -o -name "Pipfile" -o -name "pyproject.toml" | \
        head -20 > "$OUTPUT_DIR/source/python-files.txt" 2>/dev/null || true
    
    # Copy Python files
    while IFS= read -r python_file; do
        cp "$python_file" "$OUTPUT_DIR/source/python/" 2>/dev/null || true
    done < "$OUTPUT_DIR/source/python-files.txt" 2>/dev/null || true
    
    # Python bytecode decompilation
    if [[ "$HAS_UNCOMPILE6" == true ]]; then
        log "INFO" "Decompiling Python bytecode..."
        find "$OUTPUT_DIR/filesystem" -name "*.pyc" | while read -r pyc_file; do
            local output_file="${pyc_file%.pyc}.py"
            local relative_path="${output_file#$OUTPUT_DIR/filesystem/}"
            mkdir -p "$OUTPUT_DIR/source/decompiled/$(dirname "$relative_path")"
            if uncompyle6 "$pyc_file" > "$OUTPUT_DIR/source/decompiled/$relative_path" 2>/dev/null; then
                log "DEBUG" "Decompiled: $pyc_file"
            fi
        done
    fi
    
    # Node.js applications
    log "INFO" "Recovering Node.js source code..."
    find "$OUTPUT_DIR/filesystem" -name "package.json" -o -name "*.js" -o -name "*.ts" -o -name "node_modules" | \
        head -20 > "$OUTPUT_DIR/source/nodejs-files.txt" 2>/dev/null || true
    
    # Copy Node.js files
    while IFS= read -r nodejs_file; do
        if [[ -f "$nodejs_file" ]]; then
            cp "$node_file" "$OUTPUT_DIR/source/nodejs/" 2>/dev/null || true
        elif [[ -d "$nodejs_file" ]]; then
            cp -r "$nodejs_file" "$OUTPUT_DIR/source/nodejs/" 2>/dev/null || true
        fi
    done < "$OUTPUT_DIR/source/nodejs-files.txt" 2>/dev/null || true
    
    # Java applications
    log "INFO" "Recovering Java source code..."
    find "$OUTPUT_DIR/filesystem" -name "*.jar" -o -name "*.war" -o -name "*.ear" -o -name "pom.xml" -o -name "build.gradle" -o -name "*.java" | \
        head -20 > "$OUTPUT_DIR/source/java-files.txt" 2>/dev/null || true
    
    # Extract JAR files
    find "$OUTPUT_DIR/filesystem" -name "*.jar" | while read -r jar_file; do
        local jar_name=$(basename "$jar_file" .jar)
        mkdir -p "$OUTPUT_DIR/source/jar-extracted/$jar_name"
        if unzip -q "$jar_file" -d "$OUTPUT_DIR/source/jar-extracted/$jar_name" 2>/dev/null; then
            log "DEBUG" "Extracted JAR: $jar_file"
        fi
    done
    
    # Go applications
    log "INFO" "Identifying Go binaries..."
    find "$OUTPUT_DIR/filesystem" -type f -executable -exec sh -c 'file "$1" | grep -q "Go BuildID" && echo "$1"' _ {} \; | \
        head -10 > "$OUTPUT_DIR/source/go-binaries.txt" 2>/dev/null || true
    
    # Ruby applications
    log "INFO" "Recovering Ruby source code..."
    find "$OUTPUT_DIR/filesystem" -name "*.rb" -o -name "Gemfile" -o -name "config.ru" | \
        head -20 > "$OUTPUT_DIR/source/ruby-files.txt" 2>/dev/null || true
    
    # PHP applications
    log "INFO" "Recovering PHP source code..."
    find "$OUTPUT_DIR/filesystem" -name "*.php" -o -name "composer.json" | \
        head -20 > "$OUTPUT_DIR/source/php-files.txt" 2>/dev/null || true
    
    # .NET applications
    log "INFO" "Recovering .NET source code..."
    find "$OUTPUT_DIR/filesystem" -name "*.cs" -o -name "*.vb" -o -name "*.fs" -o -name "*.dll" -o -name "*.exe" -o -name "project.json" -o -name "*.csproj" | \
        head -20 > "$OUTPUT_DIR/source/dotnet-files.txt" 2>/dev/null || true
    
    # Configuration files
    log "INFO" "Recovering configuration files..."
    find "$OUTPUT_DIR/filesystem" -name "*.yml" -o -name "*.yaml" -o -name "*.xml" -o -name "*.properties" -o -name "*.conf" -o -name "*.ini" | \
        head -20 > "$OUTPUT_DIR/source/config-files.txt" 2>/dev/null || true
    
    # Generate source code summary
    log "INFO" "Generating source code summary..."
    cat > "$OUTPUT_DIR/source/source-summary.md" << EOF
# Source Code Recovery Summary

## Recovered Languages

### Python
- Files: $(wc -l < "$OUTPUT_DIR/source/python-files.txt" 2>/dev/null || echo "0")
- Decompiled: $(find "$OUTPUT_DIR/source/decompiled" -name "*.py" 2>/dev/null | wc -l || echo "0")

### Node.js
- Files: $(wc -l < "$OUTPUT_DIR/source/nodejs-files.txt" 2>/dev/null || echo "0")

### Java
- Files: $(wc -l < "$OUTPUT_DIR/source/java-files.txt" 2>/dev/null || echo "0")
- JARs extracted: $(find "$OUTPUT_DIR/source/jar-extracted" -type d 2>/dev/null | wc -l || echo "0")

### Go
- Binaries: $(wc -l < "$OUTPUT_DIR/source/go-binaries.txt" 2>/dev/null || echo "0")

### Ruby
- Files: $(wc -l < "$OUTPUT_DIR/source/ruby-files.txt" 2>/dev/null || echo "0")

### PHP
- Files: $(wc -l < "$OUTPUT_DIR/source/php-files.txt" 2>/dev/null || echo "0")

### .NET
- Files: $(wc -l < "$OUTPUT_DIR/source/dotnet-files.txt" 2>/dev/null || echo "0")

## Directory Structure
\`\`\`
 $OUTPUT_DIR/source/
â”œâ”€â”€ python/           # Python source files
â”œâ”€â”€ nodejs/           # Node.js source files
â”œâ”€â”€ jar-extracted/    # Extracted JAR files
â”œâ”€â”€ decompiled/       # Decompiled Python bytecode
â”œâ”€â”€ ruby/            # Ruby source files
â”œâ”€â”€ php/             # PHP source files
â”œâ”€â”€ dotnet/          # .NET source files
â””â”€â”€ config-files.txt # Configuration files list
\`\`\`

---
*Generated by Ultimate Docker Decomposition Framework*
EOF
    
    log "SUCCESS" "Source code recovery completed"
    
    ((COMPLETED_PHASES++))
    echo -e "\n${GREEN}âœ“ Phase 6.5 completed${NC}"
}

# =============================================================================
# REPORT GENERATION
# =============================================================================

generate_final_report() {
    log "INFO" "Generating final report..."
    
    local script_end_time=$(date +%s)
    local total_duration=$((script_end_time - SCRIPT_START_TIME))
    local hours=$((total_duration / 3600))
    local minutes=$(( (total_duration % 3600) / 60 ))
    local seconds=$((total_duration % 60))
    
    cat > "$OUTPUT_DIR/analysis/FINAL_REPORT.md" << EOF
# ðŸ”¬ Ultimate Docker Image Decomposition Report

## Mission Summary
- **Target Image**: \`$IMAGE\`
- **Analysis Date**: $(date -u +"%Y-%m-%dT%H:%M:%SZ")
- **Framework Version**: $SCRIPT_VERSION
- **Total Duration**: ${hours}h ${minutes}m ${seconds}s
- **Status**: $([ $ERROR_COUNT -eq 0 ] && echo "SUCCESS" || echo "COMPLETED WITH ISSUES")

## Mission Statistics
- **Total Phases**: $TOTAL_PHASES
- **Completed Phases**: $COMPLETED_PHASES
- **Errors Encountered**: $ERROR_COUNT
- **Warnings Generated**: $WARNING_COUNT

## Phase Results

### 1. Intelligence & Registry Reconnaissance
- **Remote Manifest**: $([ -f "$OUTPUT_DIR/metadata/remote-manifest.json" ] && echo "âœ“ Recovered" || echo "âœ— Failed")
- **Registry Info**: $([ -f "$OUTPUT_DIR/metadata/registry-info.json" ] && echo "âœ“ Recovered" || echo "âœ— Failed")

### 2. Secure Image Acquisition
- **Image Pulled**: âœ“ Success
- **Image Archive**: âœ“ Created
- **Image Metadata**: âœ“ Extracted

### 3. Dockerfile Reconstruction
- **Whaler Method**: $([ -f "$OUTPUT_DIR/dockerfile/Dockerfile.whaler" ] && echo "âœ“ Success" || echo "âœ— Failed")
- **dfimage Method**: $([ -f "$OUTPUT_DIR/dockerfile/Dockerfile.dfimage" ] && echo "âœ“ Success" || echo "âœ— Failed")
- **History Method**: âœ“ Success

### 4. Binary Forensics
- **Binaries Found**: $(wc -l < "$OUTPUT_DIR/analysis/binaries.txt" 2>/dev/null || echo "0")
- **Go Binaries**: $(wc -l < "$OUTPUT_DIR/analysis/go-binaries.txt" 2>/dev/null || echo "0")

### 5. Filesystem Extraction
- **Complete Filesystem**: âœ“ Success
- **Individual Layers**: $(find "$OUTPUT_DIR/layers" -type d -name "extracted" 2>/dev/null | wc -l || echo "0")
- **Total Files**: $(find "$OUTPUT_DIR/filesystem" -type f 2>/dev/null | wc -l || echo "0")

### 6. Configuration Recovery
- **Environment Variables**: $(wc -l < "$OUTPUT_DIR/configs/environment.txt" 2>/dev/null || echo "0")
- **Exposed Ports**: $(jq length "$OUTPUT_DIR/configs/ports.json" 2>/dev/null || echo "0")
- **Volumes**: $(jq length "$OUTPUT_DIR/configs/volumes.json" 2>/dev/null || echo "0")

### 7. Docker Compose Reconstruction
- **Compose File**: âœ“ Generated
- **K8s Manifests**: $([ -f "$OUTPUT_DIR/orchestration/deployment.yaml" ] && echo "âœ“ Generated" || echo "âœ— Failed")

### 8. SBOM & Vulnerability Analysis
- **Packages Discovered**: $(jq '.artifacts | length' "$OUTPUT_DIR/sbom/sbom.json" 2>/dev/null || echo "0")
- **Vulnerabilities Found**: $(jq '.matches | length' "$OUTPUT_DIR/vulnerabilities/vulnerabilities.json" 2>/dev/null || echo "0")

### 9. Forensic Artifact Recovery
- **Secrets Found**: $(wc -l < "$OUTPUT_DIR/forensic/secrets-found.txt" 2>/dev/null || echo "0")
- **Certificates**: $(wc -l < "$OUTPUT_DIR/forensic/certificates.txt" 2>/dev/null || echo "0")
- **SSH Keys**: $(wc -l < "$OUTPUT_DIR/forensic/ssh-keys.txt" 2>/dev/null || echo "0")

### 10. Runtime Analysis
 $([ "$SKIP_RUNTIME" == "false" ] && echo "- **Runtime Data**: âœ“ Collected" || echo "- **Runtime Data**: âš  Skipped")

### 11. Offensive Security Analysis
 $([ "$SKIP_OFFENSIVE" == "false" ] && echo "- **Security Issues**: $(wc -l < "$OUTPUT_DIR/security/security-issues.txt" 2>/dev/null || echo "0")" || echo "- **Security Analysis**: âš  Skipped")

### 12. Source Code Recovery
- **Python Files**: $(wc -l < "$OUTPUT_DIR/source/python-files.txt" 2>/dev/null || echo "0")
- **Node.js Files**: $(wc -l < "$OUTPUT_DIR/source/nodejs-files.txt" 2>/dev/null || echo "0")
- **Java Files**: $(wc -l < "$OUTPUT_DIR/source/java-files.txt" 2>/dev/null || echo "0")
- **Total Decompiled**: $(find "$OUTPUT_DIR/source/decompiled" -type f 2>/dev/null | wc -l || echo "0")

## Critical Findings

### Security Issues
 $(cat "$OUTPUT_DIR/security/security-issues.txt" 2>/dev/null || echo "None")

### Discovered Secrets
 $(head -5 "$OUTPUT_DIR/forensic/secrets-found.txt" 2>/dev/null || echo "None")

### High-Severity Vulnerabilities
 $(jq -r '.matches[] | select(.vulnerability.severity == "Critical") | "- \(.vulnerability.id): \(.artifact.name)"' "$OUTPUT_DIR/vulnerabilities/vulnerabilities.json" 2>/dev/null || echo "None")

## Directory Structure
\`\`\`
 $OUTPUT_DIR/
â”œâ”€â”€ metadata/           # Image metadata and manifests
â”œâ”€â”€ filesystem/         # Complete extracted filesystem
â”œâ”€â”€ configs/           # Configuration files and settings
â”œâ”€â”€ dockerfile/        # Reconstructed Dockerfiles
â”œâ”€â”€ compose/           # Docker Compose files
â”œâ”€â”€ orchestration/     # Kubernetes manifests
â”œâ”€â”€ sbom/             # Software Bill of Materials
â”œâ”€â”€ vulnerabilities/   # Security vulnerabilities
â”œâ”€â”€ forensic/         # Security findings and artifacts
â”œâ”€â”€ runtime/          # Runtime analysis data
â”œâ”€â”€ security/         # Security analysis results
â”œâ”€â”€ source/           # Recovered source code
â””â”€â”€ analysis/         # Analysis reports and logs
\`\`\`

## Next Steps

1. **Review Security Findings**: Examine \`security/security-issues.txt\`
2. **Analyze Vulnerabilities**: Review \`vulnerabilities/vulnerabilities.json\`
3. **Examine Secrets**: Check \`forensic/secrets-found.txt\`
4. **Review Source Code**: Browse \`source/\` directory
5. **Test Reconstruction**: Verify \`Dockerfile.reconstructed\` and \`compose/docker-compose.yml\`

## Mission Control

- **Framework**: Ultimate Docker Decomposition Framework $SCRIPT_VERSION
- **Research Date**: $RESEARCH_DATE
- **Tools Used**: Docker, jq, tar, curl, git$([ "$HAS_SYFT" == true ] && echo ", Syft")$([ "$HAS_GRYPE" == true ] && echo ", Grype")$([ "$HAS_WHALER" == true ] && echo ", Whaler")$([ "$HAS_DIVE" == true ] && echo ", Dive")$([ "$HAS_SKOPEO" == true ] && echo ", Skopeo")$([ "$HAS_CRANE" == true ] && echo ", Crane")$([ "$HAS_KOMPOSE" == true ] && echo ", Kompose")$([ "$HAS_HELM" == true ] && echo ", Helm")

---
*Report generated by Ultimate Docker Decomposition Framework*
*Mission completed at $(date -u +"%Y-%m-%dT%H:%M:%SZ")*
EOF
    
    log "SUCCESS" "Final report generated: $OUTPUT_DIR/analysis/FINAL_REPORT.md"
}

# =============================================================================
# CLEANUP FUNCTIONS
# =============================================================================

cleanup_background_processes() {
    log "INFO" "Cleaning up background processes..."
    
    for pid in "${BACKGROUND_PROCESSES[@]}"; do
        if kill -0 "$pid" 2>/dev/null; then
            kill "$pid" 2>/dev/null || true
            log "DEBUG" "Killed background process: $pid"
        fi
    done
}

# =============================================================================
# MAIN EXECUTION
# =============================================================================

main() {
    # Initialize
    SCRIPT_START_TIME=$(date +%s)
    
    # Display banner
    echo -e "${MAGENTA}"
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘                    ðŸ”¬ ULTIMATE DOCKER DECOMPOSITION FRAMEWORK               â•‘"
    echo "â•‘                            Version $SCRIPT_VERSION                            â•‘"
    echo "â•‘                         Research-Validated Toolchain                        â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${NC}"
    
    # Parse arguments
    if [[ -z "$IMAGE" ]]; then
        echo -e "${RED}Error: No image specified${NC}"
        echo "Usage: $0 <image:tag> [output_directory] [container_id]"
        echo "Example: $0 nginx:latest ./extracted abcdef123456"
        exit 1
    fi
    
    log "INFO" "Starting Ultimate Docker Decomposition Framework"
    log "INFO" "Target Image: $IMAGE"
    log "INFO" "Output Directory: $OUTPUT_DIR"
    [[ -n "$CONTAINER_ID" ]] && log "INFO" "Container ID: $CONTAINER_ID"
    
    # Check system resources
    check_system_resources
    
    # Create output structure
    log "INFO" "Creating output structure..."
    mkdir -p "$OUTPUT_DIR"/{metadata,filesystem,layers,configs/{webserver,database,application},dockerfile,compose,orchestration,sbom,vulnerabilities,forensic,runtime,security,source/{python,nodejs,jar-extracted,decompiled,ruby,php,dotnet},analysis}
    
    # Initialize log files
    LOG_FILE="$OUTPUT_DIR/analysis/decomposition.log"
    REPORT_FILE="$OUTPUT_DIR/analysis/FINAL_REPORT.md"
    METRICS_FILE="$OUTPUT_DIR/analysis/metrics.json"
    
    # Verify and install tools
    verify_and_install_tools
    
    # Execute phases
    phase0_intelligence_reconnaissance
    phase1_secure_acquisition
    phase1_5_dockerfile_reconstruction
    phase2_binary_forensics
    phase2_5_filesystem_extraction
    phase3_config_recovery
    phase3_5_compose_reconstruction
    phase4_sbom_vulnerability
    phase4_5_forensic_recovery
    phase5_runtime_analysis
    phase6_offensive_security
    phase6_5_source_recovery
    
    # Generate final report
    generate_final_report
    
    # Cleanup
    cleanup_background_processes
    
    # Display completion message
    echo -e "\n${GREEN}"
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘                           ðŸŽ‰ MISSION COMPLETED!                          â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${NC}"
    echo -e "${BLUE}Results saved to: ${YELLOW}$OUTPUT_DIR${NC}"
    echo -e "${BLUE}Final report: ${YELLOW}$OUTPUT_DIR/analysis/FINAL_REPORT.md${NC}"
    echo -e "${BLUE}Log file: ${YELLOW}$OUTPUT_DIR/analysis/decomposition.log${NC}"
    
    if [[ $ERROR_COUNT -gt 0 ]]; then
        echo -e "\n${YELLOW}âš  Mission completed with $ERROR_COUNT errors and $WARNING_COUNT warnings${NC}"
        echo -e "${YELLOW}  Check the log file for details: $LOG_FILE${NC}"
    else
        echo -e "\n${GREEN}âœ… Mission completed successfully with $WARNING_COUNT warnings${NC}"
    fi
    
    echo -e "\n${CYAN}Next steps:${NC}"
    echo "  1. Review the final report: $OUTPUT_DIR/analysis/FINAL_REPORT.md"
    echo "  2. Examine reconstructed files in $OUTPUT_DIR/"
    echo "  3. Check for security issues in $OUTPUT_DIR/security/"
    echo "  4. Review discovered secrets in $OUTPUT_DIR/forensic/"
    echo "  5. Analyze vulnerabilities in $OUTPUT_DIR/vulnerabilities/"
}

# Trap cleanup on exit
trap cleanup_background_processes EXIT

# Run main function
main "$@"
